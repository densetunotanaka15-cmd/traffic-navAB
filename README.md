# 🚦 視覚障がい者向け信号機検出ウェブアプリあプリ
このプロジェクトは、視覚障がい者の方が交通状況をより安全に理解できるように設計されたプロトタイプのウェブアプリケーションです。YOLOv8モデルを使用して画像内の信号機を検出し、その結果を音声フィードバックと高コントラスト表示で提供します。

## 機能

*   **YOLOv8による信号機検出**: 学翂済みYOLOv8モデルを用いて、アップロードされた画像内の信号機（赤、青、緑）をリアルタイムで検出します。
*   **音声フィードバック**: 検出された信号機の情報を自動的に音声で読み上げ、視覚情報に頼らずに状況を把握できます。
*   **高コントラスト表示**: 検出結果のテキスト表示は、視認性を高めるために高コントラストで表示されます。
*   **画像アップロード**: ユーザーはデバイスから画像をアップロードし、信号機検出を実行できます。

## セットアップ

このアプリケーションをローカルで実行するには、以下の手順に従ってください。

### 1. リポジトリのクローン

```bash
git clone <your-repository-url>
cd <your-repository-name>
```

### 2. Python環境の準備

Python 3.8以上の環境を推奨します。仮想環境を作成することをお勧めします。

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
vvenv\Scripts\activate    # Windows
```

### 3. 必要なライブラリのインストール

`requirements.txt`ファイルを使用して、必要なすべてのPythonライブラリをインストールします。

```bash
pip install -r requirements.txt
```

### 4. 学翂済みモデルの配置

YOLOv8モデルの学翂済みウェイトファイル `best.pt` を適切なパスに配置してください。このアプリケーションでは、モデルが `/content/runs/detect/train2/weights/best.pt` にあることを想定しています。必要に応じて、`app.py` 内の `model_path` 変数を更新してください。

## アプリケーションの実行

セットアップが完了したら、Streamlitアプリケーションを起動できます。

```bash
streamlit run app.py
```

アプリケーションはブラウザで自動的に開きます。

## 使用方法

1.  ウェブアプリケーションにアクセスします。
2.  「Upload Image」セクションで、「Choose an image...」ボタンをクリックし、検出したい画像を選択してアップロードします。
3.  画像がアップロードされると、YOLOv8モデルが信号機を検出し、検出結果が画像上にバウンディングボックスとラベルで表示されます。
4.  検出された信号機の情報は、テキスト（高コントラストで表示）と音声フィードバックで提供されます。
5.  サイドバーの「Accessibility Settings」で、音声フィードバックの有効/無効や言語（英語/日本語）を切り替えることができます。

**注意**: 現在、ライブカメラフィード機能は開発中です。
